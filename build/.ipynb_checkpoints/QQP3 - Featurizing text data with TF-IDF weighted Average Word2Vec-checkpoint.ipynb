{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Featurizing text data with TF-IDF weighted word-vectors and Avg.word-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will only operate on the first 100k points as 8GB RAM is not enough.\n",
    "\n",
    "# Library imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# We can extract word2vec vectors using spacy\n",
    "# If there are any dependency issues, please folow these links:\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use the following function to time our code:\n",
    "def time_taken(start_time):\n",
    "    print(\"~> Time taken:\",\n",
    "         round(time()-start_time, 2), \"seconds\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will import more libraries as and when required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 0.42 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time()\n",
    "\n",
    "# Import sample from the original dataset:\n",
    "df = pd.read_csv(\"../train/train.csv\", nrows=100000)\n",
    "\n",
    "# Encode all the questions to unicode format:\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))\n",
    "\n",
    "time_taken(st)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 Computing TF-IDF weighted Average Word2Vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Merge texts into a single list:\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "# Create TfidfVectorizer instance:\n",
    "tfidf = TfidfVectorizer(lowercase=False)\n",
    "\n",
    "# Get the parameters in tfidf instance:\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 3.13 seconds\n"
     ]
    }
   ],
   "source": [
    "st =time()\n",
    "\n",
    "# Now apply tfidf transform:\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "time_taken(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 0.08 seconds\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "\n",
    "# We will now take all the tf-idf vectored values into a dictionary:\n",
    "# key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "\n",
    "time_taken(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have the TF-IDF Scores. We will now convert each question to a weighted average of word2vec vectors by using these TF-IDF Scores.\n",
    "- We use a pre-trained GLoVe model which comes free with spacy library. The model itself is trained on Wikipedia data. More about the pre-trained model @ https://spacy.io/usage/vectors-similarity\n",
    "- Because it is trained on Wikipedia, the model is strong in terms of word semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can either load and use 'en_vectors_web_lg' or 'en_core_web_sm'.\n",
    "# The difference between the two is that, 'en_core_web_sm' is a smaller\n",
    "# model compared to 'en_vectors_web_lg'\n",
    "\n",
    "# If the system has less RAM, it is better to load 'en_core_web_sm' model\n",
    "# as the word-vector. The only disadvantage with a smaller model is that\n",
    "# it will give us similarity vectors with lesser accuracy.\n",
    "\n",
    "# Note: there are 2 full version models of word2vec models trained on\n",
    "# wikipedia data. One of them is 'en_core_web_lg' and the other one is \n",
    "# 'en_vectors_web_lg'. If we want to make changes to the word2vec model,\n",
    "# then we can load the 'en_vectors_web_lg' word2vec model, otherwise, we \n",
    "# go with 'en_core_web_lg' word2vec model.\n",
    "\n",
    "# Note: We can't load these pre-trained word2vec models unless and until\n",
    "# we download the models through the console of the system.\n",
    "\n",
    "    ############################################### \n",
    "    # Syntax: python -m spacy download model_name #\n",
    "    ###############################################\n",
    "    \n",
    "# Example: python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 100000/100000 [19:04<00:00, 87.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading the smaller model:\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "st = time()\n",
    "\n",
    "vector1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar.\n",
    "for q1 in tqdm(list(df.question1)):\n",
    "    doc = nlp(q1) \n",
    "    # 384 dimensional vector\n",
    "    mean_vec1 = np.zeros([len(doc), 384])\n",
    "    for word in doc:\n",
    "        # word2vec:\n",
    "        vec1 = word.vector\n",
    "        \n",
    "        # Fetch the tf-idf score:\n",
    "        try:\n",
    "            idf = word2tfidf[str(word)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        \n",
    "        # Compute final vector:\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vector1.append(mean_vec1)\n",
    "df['q1_feats_m'] = list(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 1144.88 seconds\n"
     ]
    }
   ],
   "source": [
    "time_taken(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 100000/100000 [19:29<00:00, 85.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 1170.01 seconds\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "\n",
    "vector2 = []\n",
    "for q2 in tqdm(list(df.question2)):\n",
    "    doc = nlp(q2)\n",
    "    mean_vec2 = np.zeros([len(doc), 384])\n",
    "    for word in doc:\n",
    "        # word2vec:\n",
    "        vec2 = word.vector\n",
    "        # Fetch idf score:\n",
    "        try:\n",
    "            idf = word2tfidf[str(word)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # Compute final vector:\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vector2.append(mean_vec2)\n",
    "\n",
    "df['q2_feats_m'] = list(vector2)\n",
    "\n",
    "time_taken(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<idx>. <Filename>\n",
      "0. .ipynb_checkpoints\n",
      "1. df_fe_without_preprocessing_train.csv\n",
      "2. nlp_features_train.csv\n",
      "3. QQP1 - BasicEDA, TextPreprocessing, BasicFeaturization, AdvancedFeaturization (NLP & Fuzzy featurization).ipynb\n",
      "4. QQP1.py\n",
      "5. QQP2 - Word Cloud, PCA & t-SNE 2D and 3D Visualizations of Engineered Features.ipynb\n",
      "6. QQP2.py\n",
      "7. QQP3 - Featurizing text data with TF-IDF weighted Average Word2Vec.ipynb\n",
      "8. quora.png\n",
      "9. train_dup_question_pairs.txt\n",
      "10. train_non_dup_question_pairs.txt\n"
     ]
    }
   ],
   "source": [
    "# Get the files in the current working directory\n",
    "files_in_cwd = os.listdir()\n",
    "index = 0\n",
    "print(\"<idx>. <Filename>\")\n",
    "for f in files_in_cwd:\n",
    "    print(\"{}. {}\".format(index, f))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 1.55 seconds\n"
     ]
    }
   ],
   "source": [
    "# We will read some previously saved .csv files like:\n",
    "# 1. nlp_features_train.csv\n",
    "# 2. df_fe_without_preprocessing_train.csv\n",
    "# and we will use the data generated now and finally merge all of the data into \n",
    "# a single pandas dataframe. The dataframe size may get really large.\n",
    "\n",
    "st = time()\n",
    "# Load the nlp_features_train.csv file into a dataframe:\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    df_nlp = pd.read_csv(\"nlp_features_train.csv\", encoding='latin-1', nrows=100000)\n",
    "else:\n",
    "    print('Generate the file by running the code in QQP1.')\n",
    "\n",
    "# Load the df_fe_without_preprocessing_train.csv file into a dataframe:\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    df_pre = pd.read_csv('df_fe_without_preprocessing_train.csv', encoding=\\\n",
    "                        'latin-1', nrows=100000)\n",
    "else:\n",
    "    print('Generate the file by running the code in QQP1.')\n",
    "\n",
    "time_taken(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 21)\n",
      "(100000, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_parital_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1   1             0  0.799984  0.399996  0.749981  0.599988  0.699993   \n",
       "2   2             0  0.399992  0.333328  0.399992  0.249997  0.399996   \n",
       "3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "0  0.785709           0.0            1.0           0.0      13.0   \n",
       "1  0.466664           0.0            1.0           0.0      12.5   \n",
       "2  0.285712           0.0            1.0           0.0      12.0   \n",
       "3  0.000000           0.0            0.0           0.0      12.0   \n",
       "4  0.307690           0.0            1.0           0.0      10.0   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_parital_ratio  \\\n",
       "0              100                93          93                 100   \n",
       "1               86                63          66                  75   \n",
       "2               63                63          43                  47   \n",
       "3               28                24           9                  14   \n",
       "4               67                47          35                  56   \n",
       "\n",
       "   longest_substr_ratio  \n",
       "0              0.982759  \n",
       "1              0.596154  \n",
       "2              0.166667  \n",
       "3              0.039216  \n",
       "4              0.175000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_nlp.shape)\n",
    "print(df_pre.shape)\n",
    "# We will drop the unnecessary features and only keep the required ones:\n",
    "df1 = df_nlp.drop(['qid1', 'qid2', 'question1', 'question2'], axis=1)\n",
    "\n",
    "# df1 corresponds to advanced nlp and fuzzy engineered features:\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \\\n",
       "0   0          1          1     66     57          14          12   \n",
       "1   1          4          1     51     88           8          13   \n",
       "2   2          1          1     73     59          14          10   \n",
       "3   3          1          1     50     65          11           9   \n",
       "4   4          3          1     76     39          13           7   \n",
       "\n",
       "   word_Common  word_Total  word_share  freq_q1+q2  freq_q1-q2  \n",
       "0         10.0        23.0    0.434783           2           0  \n",
       "1          4.0        20.0    0.200000           5           3  \n",
       "2          4.0        24.0    0.166667           2           0  \n",
       "3          0.0        19.0    0.000000           2           0  \n",
       "4          2.0        20.0    0.100000           4           2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_pre.drop(['qid1', 'qid2', 'question1', 'question2','is_duplicate'],\\\n",
    "                  axis=1)\n",
    "\n",
    "# df2 corresponds to basic engineered features:\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_feats_m</th>\n",
       "      <th>q2_feats_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[122.490798712, 100.359120488, 72.0331508666, ...</td>\n",
       "      <td>[126.564217329, 96.0618406534, 42.2021160275, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-74.5846772194, 53.8620963991, 81.0885115862,...</td>\n",
       "      <td>[-105.099983424, 79.1588504314, 77.5340879094,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.10626339912, 73.7096084356, 14.3268437684,...</td>\n",
       "      <td>[6.49532223493, 16.2452982366, 2.65493392944, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.90131050348, -34.4693912566, 48.9884575009,...</td>\n",
       "      <td>[38.9078674316, 43.9539289773, -24.3469197154,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>[48.4207775295, 38.2941785157, 121.9611063, 54...</td>\n",
       "      <td>[31.6172962189, 62.5719087124, 1.96994256973, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                          q1_feats_m  \\\n",
       "0  [122.490798712, 100.359120488, 72.0331508666, ...   \n",
       "1  [-74.5846772194, 53.8620963991, 81.0885115862,...   \n",
       "2  [-5.10626339912, 73.7096084356, 14.3268437684,...   \n",
       "3  [5.90131050348, -34.4693912566, 48.9884575009,...   \n",
       "4  [48.4207775295, 38.2941785157, 121.9611063, 54...   \n",
       "\n",
       "                                          q2_feats_m  \n",
       "0  [126.564217329, 96.0618406534, 42.2021160275, ...  \n",
       "1  [-105.099983424, 79.1588504314, 77.5340879094,...  \n",
       "2  [6.49532223493, 16.2452982366, 2.65493392944, ...  \n",
       "3  [38.9078674316, 43.9539289773, -24.3469197154,...  \n",
       "4  [31.6172962189, 62.5719087124, 1.96994256973, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our original dataset with some additional features:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q1_feats_m</th>\n",
       "      <th>q2_feats_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[122.490798712, 100.359120488, 72.0331508666, ...</td>\n",
       "      <td>[126.564217329, 96.0618406534, 42.2021160275, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-74.5846772194, 53.8620963991, 81.0885115862,...</td>\n",
       "      <td>[-105.099983424, 79.1588504314, 77.5340879094,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-5.10626339912, 73.7096084356, 14.3268437684,...</td>\n",
       "      <td>[6.49532223493, 16.2452982366, 2.65493392944, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[5.90131050348, -34.4693912566, 48.9884575009,...</td>\n",
       "      <td>[38.9078674316, 43.9539289773, -24.3469197154,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[48.4207775295, 38.2941785157, 121.9611063, 54...</td>\n",
       "      <td>[31.6172962189, 62.5719087124, 1.96994256973, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         q1_feats_m  \\\n",
       "0   0  [122.490798712, 100.359120488, 72.0331508666, ...   \n",
       "1   1  [-74.5846772194, 53.8620963991, 81.0885115862,...   \n",
       "2   2  [-5.10626339912, 73.7096084356, 14.3268437684,...   \n",
       "3   3  [5.90131050348, -34.4693912566, 48.9884575009,...   \n",
       "4   4  [48.4207775295, 38.2941785157, 121.9611063, 54...   \n",
       "\n",
       "                                          q2_feats_m  \n",
       "0  [126.564217329, 96.0618406534, 42.2021160275, ...  \n",
       "1  [-105.099983424, 79.1588504314, 77.5340879094,...  \n",
       "2  [6.49532223493, 16.2452982366, 2.65493392944, ...  \n",
       "3  [38.9078674316, 43.9539289773, -24.3469197154,...  \n",
       "4  [31.6172962189, 62.5719087124, 1.96994256973, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will drop ['qid1','qid2','question1','question2','is_duplicate'] from df:\n",
    "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'], axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 14.04 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.490799</td>\n",
       "      <td>100.359120</td>\n",
       "      <td>72.033151</td>\n",
       "      <td>115.891096</td>\n",
       "      <td>-48.144981</td>\n",
       "      <td>34.736722</td>\n",
       "      <td>-172.386330</td>\n",
       "      <td>-93.059744</td>\n",
       "      <td>113.417203</td>\n",
       "      <td>51.259765</td>\n",
       "      <td>...</td>\n",
       "      <td>12.462868</td>\n",
       "      <td>41.063396</td>\n",
       "      <td>8.037371</td>\n",
       "      <td>-15.198150</td>\n",
       "      <td>18.056487</td>\n",
       "      <td>6.217941</td>\n",
       "      <td>-30.221076</td>\n",
       "      <td>3.659344</td>\n",
       "      <td>-1.687294</td>\n",
       "      <td>-1.825006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-74.584677</td>\n",
       "      <td>53.862096</td>\n",
       "      <td>81.088512</td>\n",
       "      <td>98.550397</td>\n",
       "      <td>-50.356915</td>\n",
       "      <td>53.286622</td>\n",
       "      <td>-37.665547</td>\n",
       "      <td>-82.297257</td>\n",
       "      <td>45.744834</td>\n",
       "      <td>-8.385913</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.548015</td>\n",
       "      <td>-11.906959</td>\n",
       "      <td>20.344241</td>\n",
       "      <td>1.829228</td>\n",
       "      <td>-16.460159</td>\n",
       "      <td>-5.656435</td>\n",
       "      <td>-10.035233</td>\n",
       "      <td>-4.768943</td>\n",
       "      <td>-12.692666</td>\n",
       "      <td>-5.208524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.106263</td>\n",
       "      <td>73.709608</td>\n",
       "      <td>14.326844</td>\n",
       "      <td>104.493053</td>\n",
       "      <td>1.258413</td>\n",
       "      <td>35.409146</td>\n",
       "      <td>-149.265339</td>\n",
       "      <td>-97.636930</td>\n",
       "      <td>42.259155</td>\n",
       "      <td>51.435161</td>\n",
       "      <td>...</td>\n",
       "      <td>3.012211</td>\n",
       "      <td>14.140741</td>\n",
       "      <td>-2.977540</td>\n",
       "      <td>-3.214739</td>\n",
       "      <td>4.373585</td>\n",
       "      <td>2.911802</td>\n",
       "      <td>-20.323167</td>\n",
       "      <td>9.798284</td>\n",
       "      <td>11.907082</td>\n",
       "      <td>-8.814535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.901311</td>\n",
       "      <td>-34.469391</td>\n",
       "      <td>48.988458</td>\n",
       "      <td>59.481399</td>\n",
       "      <td>40.695803</td>\n",
       "      <td>-41.397960</td>\n",
       "      <td>-36.726121</td>\n",
       "      <td>24.031034</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>-29.501785</td>\n",
       "      <td>...</td>\n",
       "      <td>13.059348</td>\n",
       "      <td>1.411459</td>\n",
       "      <td>-1.874297</td>\n",
       "      <td>-7.867466</td>\n",
       "      <td>17.947856</td>\n",
       "      <td>12.057635</td>\n",
       "      <td>-10.482685</td>\n",
       "      <td>5.230752</td>\n",
       "      <td>10.150245</td>\n",
       "      <td>5.845988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.420778</td>\n",
       "      <td>38.294179</td>\n",
       "      <td>121.961106</td>\n",
       "      <td>54.678226</td>\n",
       "      <td>-45.466374</td>\n",
       "      <td>38.553049</td>\n",
       "      <td>-294.462586</td>\n",
       "      <td>-105.776589</td>\n",
       "      <td>103.886341</td>\n",
       "      <td>65.766421</td>\n",
       "      <td>...</td>\n",
       "      <td>13.320748</td>\n",
       "      <td>42.630676</td>\n",
       "      <td>11.245030</td>\n",
       "      <td>-21.892262</td>\n",
       "      <td>43.775802</td>\n",
       "      <td>8.189654</td>\n",
       "      <td>-34.812249</td>\n",
       "      <td>8.047953</td>\n",
       "      <td>9.497889</td>\n",
       "      <td>5.378521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1           2           3          4          5    \\\n",
       "0  122.490799  100.359120   72.033151  115.891096 -48.144981  34.736722   \n",
       "1  -74.584677   53.862096   81.088512   98.550397 -50.356915  53.286622   \n",
       "2   -5.106263   73.709608   14.326844  104.493053   1.258413  35.409146   \n",
       "3    5.901311  -34.469391   48.988458   59.481399  40.695803 -41.397960   \n",
       "4   48.420778   38.294179  121.961106   54.678226 -45.466374  38.553049   \n",
       "\n",
       "          6           7           8          9      ...           374  \\\n",
       "0 -172.386330  -93.059744  113.417203  51.259765    ...     12.462868   \n",
       "1  -37.665547  -82.297257   45.744834  -8.385913    ...    -21.548015   \n",
       "2 -149.265339  -97.636930   42.259155  51.435161    ...      3.012211   \n",
       "3  -36.726121   24.031034    0.295455 -29.501785    ...     13.059348   \n",
       "4 -294.462586 -105.776589  103.886341  65.766421    ...     13.320748   \n",
       "\n",
       "         375        376        377        378        379        380       381  \\\n",
       "0  41.063396   8.037371 -15.198150  18.056487   6.217941 -30.221076  3.659344   \n",
       "1 -11.906959  20.344241   1.829228 -16.460159  -5.656435 -10.035233 -4.768943   \n",
       "2  14.140741  -2.977540  -3.214739   4.373585   2.911802 -20.323167  9.798284   \n",
       "3   1.411459  -1.874297  -7.867466  17.947856  12.057635 -10.482685  5.230752   \n",
       "4  42.630676  11.245030 -21.892262  43.775802   8.189654 -34.812249  8.047953   \n",
       "\n",
       "         382       383  \n",
       "0  -1.687294 -1.825006  \n",
       "1 -12.692666 -5.208524  \n",
       "2  11.907082 -8.814535  \n",
       "3  10.150245  5.845988  \n",
       "4   9.497889  5.378521  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q1_feats_m has each row as a list. Therefore, we will extract it into a \n",
    "# dataframe as:\n",
    "st = time()\n",
    "df_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index = df3.index)\n",
    "time_taken(st)\n",
    "df_q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 14.85 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.564217</td>\n",
       "      <td>96.061841</td>\n",
       "      <td>42.202116</td>\n",
       "      <td>95.969994</td>\n",
       "      <td>-37.314082</td>\n",
       "      <td>39.737327</td>\n",
       "      <td>-148.516119</td>\n",
       "      <td>-88.340872</td>\n",
       "      <td>110.552041</td>\n",
       "      <td>62.843040</td>\n",
       "      <td>...</td>\n",
       "      <td>16.188503</td>\n",
       "      <td>33.233713</td>\n",
       "      <td>6.971700</td>\n",
       "      <td>-14.820828</td>\n",
       "      <td>15.534945</td>\n",
       "      <td>8.205955</td>\n",
       "      <td>-25.256606</td>\n",
       "      <td>1.552828</td>\n",
       "      <td>1.651827</td>\n",
       "      <td>0.267462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-105.099983</td>\n",
       "      <td>79.158850</td>\n",
       "      <td>77.534088</td>\n",
       "      <td>58.330385</td>\n",
       "      <td>-41.438078</td>\n",
       "      <td>115.591662</td>\n",
       "      <td>-142.872375</td>\n",
       "      <td>-125.501038</td>\n",
       "      <td>23.816001</td>\n",
       "      <td>25.313954</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.432317</td>\n",
       "      <td>-4.367793</td>\n",
       "      <td>41.101273</td>\n",
       "      <td>-0.930737</td>\n",
       "      <td>-15.686246</td>\n",
       "      <td>-7.275999</td>\n",
       "      <td>2.756560</td>\n",
       "      <td>-7.351970</td>\n",
       "      <td>3.103773</td>\n",
       "      <td>0.440425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.495322</td>\n",
       "      <td>16.245298</td>\n",
       "      <td>2.654934</td>\n",
       "      <td>86.827784</td>\n",
       "      <td>-34.626589</td>\n",
       "      <td>95.729673</td>\n",
       "      <td>-123.613627</td>\n",
       "      <td>-115.022091</td>\n",
       "      <td>53.958783</td>\n",
       "      <td>61.496209</td>\n",
       "      <td>...</td>\n",
       "      <td>8.264448</td>\n",
       "      <td>-2.244750</td>\n",
       "      <td>11.084606</td>\n",
       "      <td>-16.741266</td>\n",
       "      <td>14.854023</td>\n",
       "      <td>15.726977</td>\n",
       "      <td>-1.298039</td>\n",
       "      <td>14.340431</td>\n",
       "      <td>11.669012</td>\n",
       "      <td>10.423255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.907867</td>\n",
       "      <td>43.953929</td>\n",
       "      <td>-24.346920</td>\n",
       "      <td>86.120009</td>\n",
       "      <td>0.079079</td>\n",
       "      <td>-9.801455</td>\n",
       "      <td>-60.949873</td>\n",
       "      <td>-37.361491</td>\n",
       "      <td>49.504973</td>\n",
       "      <td>-22.386544</td>\n",
       "      <td>...</td>\n",
       "      <td>3.488654</td>\n",
       "      <td>3.906499</td>\n",
       "      <td>13.387563</td>\n",
       "      <td>-6.640244</td>\n",
       "      <td>6.378005</td>\n",
       "      <td>6.028185</td>\n",
       "      <td>2.511873</td>\n",
       "      <td>-3.830347</td>\n",
       "      <td>5.421078</td>\n",
       "      <td>6.161891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.617296</td>\n",
       "      <td>62.571909</td>\n",
       "      <td>1.969943</td>\n",
       "      <td>36.472732</td>\n",
       "      <td>-45.163165</td>\n",
       "      <td>66.659808</td>\n",
       "      <td>-105.894651</td>\n",
       "      <td>-22.777562</td>\n",
       "      <td>59.957627</td>\n",
       "      <td>62.017545</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.440844</td>\n",
       "      <td>11.887040</td>\n",
       "      <td>8.019029</td>\n",
       "      <td>-15.028031</td>\n",
       "      <td>8.280575</td>\n",
       "      <td>1.703147</td>\n",
       "      <td>-6.503707</td>\n",
       "      <td>11.263387</td>\n",
       "      <td>11.556818</td>\n",
       "      <td>2.500520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4           5    \\\n",
       "0  126.564217  96.061841  42.202116  95.969994 -37.314082   39.737327   \n",
       "1 -105.099983  79.158850  77.534088  58.330385 -41.438078  115.591662   \n",
       "2    6.495322  16.245298   2.654934  86.827784 -34.626589   95.729673   \n",
       "3   38.907867  43.953929 -24.346920  86.120009   0.079079   -9.801455   \n",
       "4   31.617296  62.571909   1.969943  36.472732 -45.163165   66.659808   \n",
       "\n",
       "          6           7           8          9      ...            374  \\\n",
       "0 -148.516119  -88.340872  110.552041  62.843040    ...      16.188503   \n",
       "1 -142.872375 -125.501038   23.816001  25.313954    ...      -4.432317   \n",
       "2 -123.613627 -115.022091   53.958783  61.496209    ...       8.264448   \n",
       "3  -60.949873  -37.361491   49.504973 -22.386544    ...       3.488654   \n",
       "4 -105.894651  -22.777562   59.957627  62.017545    ...      -2.440844   \n",
       "\n",
       "         375        376        377        378        379        380  \\\n",
       "0  33.233713   6.971700 -14.820828  15.534945   8.205955 -25.256606   \n",
       "1  -4.367793  41.101273  -0.930737 -15.686246  -7.275999   2.756560   \n",
       "2  -2.244750  11.084606 -16.741266  14.854023  15.726977  -1.298039   \n",
       "3   3.906499  13.387563  -6.640244   6.378005   6.028185   2.511873   \n",
       "4  11.887040   8.019029 -15.028031   8.280575   1.703147  -6.503707   \n",
       "\n",
       "         381        382        383  \n",
       "0   1.552828   1.651827   0.267462  \n",
       "1  -7.351970   3.103773   0.440425  \n",
       "2  14.340431  11.669012  10.423255  \n",
       "3  -3.830347   5.421078   6.161891  \n",
       "4  11.263387  11.556818   2.500520  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q12_feats_m has each row as a list. Therefore, we will extract it into a \n",
    "# dataframe as:\n",
    "st = time()\n",
    "df_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index = df3.index)\n",
    "time_taken(st)\n",
    "df_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in nlp dataframe: 17\n",
      "Number of features in preprocessed dataframe: 12\n",
      "Number of features in question1 w2v dataframe: 384\n",
      "Number of features in question2 w2v dataframe: 384\n",
      "Number of features in the final dataframe: 797\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features in nlp dataframe:\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe:\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v dataframe:\", df_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v dataframe:\", df_q2.shape[1])\n",
    "print(\"Number of features in the final dataframe:\",\\\n",
    "      df1.shape[1] + df2.shape[1] + df_q1.shape[1] + df_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~> Time taken: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "\n",
    "# The following code might take some time to execute, depending on the system\n",
    "# configuration.\n",
    "if not os.path.isfile('final_features_100k.csv'):\n",
    "    \n",
    "    # Attach 'id' attribute to question1 and question2 w2v vectors:\n",
    "    df_q1['id'] = df1['id']\n",
    "    df_q2['id'] = df1['id']\n",
    "    \n",
    "    # Merge nlp_features with preprocessing_features:\n",
    "    df1 = df1.merge(df2, on='id', how='left')\n",
    "    \n",
    "    # Merge question1 and question2 w2v vectors and save them in df2 variable:\n",
    "    df2 = df_q1.merge(df_q2, on='id', how='left')\n",
    "    \n",
    "    # We will now merge df1 and df2 into result:\n",
    "    result = df1.merge(df2, on='id', how='left')\n",
    "    \n",
    "    # Save as a .csv file to use when applying k-NN to classify the points:\n",
    "    result.to_csv('final_features_100k.csv')\n",
    "\n",
    "time_taken(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_features_100k.csv file is generated, which is of 1.37GB.\n",
    "The file will be used to apply k-NN, so that we will be able to know how accurate the k-NN classifier is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
